Rigor
=====
Kevin Rauwolf <kevin@blindsight.com>

Introduction
------------
Rigor is a framework for testing algorithms in a systematic fashion.  Users can import annotated images into the database, then run an algorithm against each of them in turn, finally producing a report that can be used for evaluating the algorithm.

Images, once imported, are stored in a file tree using a unique identifier.  A separate set of database tables contain the image metadata, keyed to the image files using the same identifier.  Aside from image-specific attributes (size, depth, source, sensor, etc.), images can also have any number of tags.  Tags are there to assist users in building sets of images, which can be useful for more detailed analysis of algorithms.

Each image can also have a number of annotations.  Annotating an image defines the ground truth in a particular domain, such as whether the image is blurry, where text is located, or what denomination bill is shown.  A single image can have annotations in different domains, and it can even have multiple annotations in the same domain (generally used when an annotation contains a boundary, and multiple ROIs exist).

When running Rigor, by default all images and annotations in a particular will be run against the algorithm.  This can be limited to a smaller sample using the command-line tools, or much more extensively tweaked by writing a standalone Python application which includes the Rigor libraries.

Prerequisites
-------------
- Python v2.7 or higher
- OpenCV 2.x Python bindings
- psycopg2
- image repository on Ea mounted locally, read-only
- exiv2 for Python (import only)
- import repository on Ea mounted locally, read-write (import only)

Configuration
-------------
Copy the `rigor.ini.sample` file to `.rigor.ini` in your home directory.  Commented-out values reflect the defaults; uncomment and change them to alter settings.

- The `image_repository` is the local path where you keep your image repository (or mount a remote one locally)

You may need to set the `PYTHONPATH` to include the `python` directory in `rigor`, plus any other Python modules such as OpenCV's.

You may also need to set the `LD_LIBRARY_PATH` or `DYLD_LIBRARY_PATH` to point to any compiled algorithms.

If you are planning on importing images, you will also want to set the upload repository read-write, and set the `upload_repository` parameter to point there.

Use
---
Running
~~~~~~~
This needs to be documented better.  See the `python/examples` directory for some basic demonstrations.

Importing
~~~~~~~~~
Importing images basically entails copying the image file into the repository, and updating the database with metadata, tags, and annotations.  There is an import script that will do most of this automatically, when supplied with a basic metadata description file.

CAUTION: Importing images into the database should be done carefully, as it is not always easy to undo mistakes.

The `import.py` command takes a single directory, or a list of directories, and imports all of the images inside.  It expects to find a `metadata.json` file inside each directory containing metadata that applies to every file.

Here is an example file with all of the metadata fields used.  Most are optional, but it is highly recommended to fill in as much information as is known, as that improves the quality of the database.

.Example `metadata.json` file
..............................................
{
  "source" : "Berkeley 2011-02",           <1>
  "sensor" : "HTC Nexus One",              <2>
  "timestamp" : "2011-02-04T21:24:56Z",    <3>
  "location" : [ -122.269241, 37.871104 ], <4>
  "tags" : [                               <5>
    "training",
    "money",
    "obscured"
  ],
  "annotations" : [
    {
      "domain" : "money",                  <6>
      "rank" : 2,                          <7>
      "model" : "20d",                     <8>
      "boundary" : [                       <9>
        [1, 2],
        [2, 4],
        [2, 8],
        [6, 7]
      ]
      "annotation_tags" : [
        "blindsight_created",
        "byhand",
        "multiple_words"
      ],
    }
  ]
}
..............................................

<1> Where the image came from, useful for getting more details later
<2> The device used to capture the image.  Will be extracted from EXIF if it's present and not supplied here.
<3> The time and date (UTC) that the image was taken.  The file timestamp will be used if this is not supplied here.
<4> WGS84 lon/lat Where the image was taken.  Ideally, this can be extracted from EXIF data, but at the moment this isn't supported
<5> Tags are freeform.  The more the merrier.
<6> Domain is a sort of namespace for the annotation.  The algorithm to test is chosen by the domain.
<7> Rank is used when multiple models have the same meaning.  A lower rank is more likely to be encountered in the wild.
<8> The model is the actual ground truth used to compare against the returned value from an algorithm.
<9> The boundary is a list of coordinates, each defining a point in a polygonal bounding box.

Here is a very basic metadata file.  While as much information as possible should be included in the metadata file, in some cases it may not be available.  The attributes below should be considered the bare minimum for metadata:

.Example minimal `metadata.json` file
..............................................
{
  "source" : "Berkeley 2011-02",
  "tags" : [
    "training",
    "money",
    "obscured"
  ]
}
..............................................

It is also possible to supply a metadata file for each image.  Create a file with the same name as the image, but with `.json` as the extension.  For example, `img00010.jpg` would have an accompanying `img00010.json` metadata file.  Anything in this file will replace anything in the directory-wide `metadata.json` file, which will replace anything automatically extracted from the image.

Once you run the `import.py` command, the images in the directory will be put into the database, and the source images will be either copied or moved to the upload tree.  Periodically, those files will be moved into the official image tree, and they will then be usable.  At the moment, that does mean a discrepency between the contents of the database and the filesystem, but it should be a short-lived difference.  It may be fixed in the future by flagging newly-uploaded data in the database, and preventing it from being used in Rigor trials until it is marked as active.
